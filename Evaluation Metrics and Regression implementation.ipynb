{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THEORITICAL:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ***What does R-squared represent in a regression model?***\n",
    "*Answer-*\n",
    "\n",
    "R-squared, also known as the coefficient of determination, represents the proportion of variance in the dependent variable (response) that is explained by the independent variables (predictors) in a regression model. It provides a measure of how well the model fits the data.\n",
    "\n",
    "### Key Points:\n",
    "- **Value Range**: R-squared ranges from 0 to 1:\n",
    "  - **0**: The model does not explain any of the variance in the dependent variable.\n",
    "  - **1**: The model perfectly explains all the variance in the dependent variable.\n",
    "- **Interpretation**: A higher R-squared value indicates a better fit of the model to the data, but it does not guarantee a good model, as it does not account for overfitting or the inclusion of irrelevant variables.\n",
    "- **Caution**: R-squared cannot determine whether the regression model is appropriate or whether the predictors are significant. It is important to also evaluate adjusted R-squared, residual plots, and statistical tests.\n",
    "\n",
    "For example, if an R-squared value is 0.75, it means that 75% of the variation in the dependent variable is explained by the predictors included in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ***What are the assumptions of linear regression?***\n",
    "*Answer-*\n",
    "\n",
    "Linear regression relies on several key assumptions to ensure that the model provides valid, reliable, and interpretable results. Violating these assumptions can lead to biased or inaccurate predictions and interpretations. Here are the assumptions:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Linearity**:\n",
    "   - The relationship between the independent variables (predictors) and the dependent variable (response) is linear.\n",
    "   - **How to check**: Plot the residuals against the predicted values. A random scatter of residuals indicates linearity.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Independence of Errors (No Autocorrelation)**:\n",
    "   - The residuals (errors) are independent of each other.\n",
    "   - This assumption is particularly important for time-series data.\n",
    "   - **How to check**: Use the Durbin-Watson test to detect autocorrelation in the residuals.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Homoscedasticity (Constant Variance of Errors)**:\n",
    "   - The variance of residuals is constant across all levels of the independent variables.\n",
    "   - Violations of this assumption lead to heteroscedasticity, which can make confidence intervals and hypothesis tests unreliable.\n",
    "   - **How to check**: Create a residual plot. A funnel shape in the plot may indicate heteroscedasticity.\n",
    "   - **How to fix**: Use transformations (e.g., log, square root) or weighted least squares regression.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Normality of Errors**:\n",
    "   - The residuals are normally distributed.\n",
    "   - This assumption is critical for valid hypothesis testing (e.g., p-values, confidence intervals).\n",
    "   - **How to check**:\n",
    "     - Plot a Q-Q plot.\n",
    "     - Perform statistical tests like the Shapiro-Wilk test or Kolmogorov-Smirnov test.\n",
    "   - **How to fix**: Use data transformations or nonparametric methods if residuals are not normal.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **No Multicollinearity**:\n",
    "   - The independent variables should not be highly correlated with each other.\n",
    "   - Multicollinearity can make it difficult to determine the individual effect of each predictor on the response variable and can lead to unstable coefficient estimates.\n",
    "   - **How to check**: Calculate the Variance Inflation Factor (VIF). A VIF > 10 typically indicates multicollinearity.\n",
    "   - **How to fix**:\n",
    "     - Remove or combine correlated predictors.\n",
    "     - Use dimensionality reduction techniques like Principal Component Analysis (PCA).\n",
    "     - Apply regularization methods like Ridge or Lasso regression.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Outliers and Influential Points** (Not an official assumption but important to address):\n",
    "   - Outliers can distort the regression line, and influential points can disproportionately affect model parameters.\n",
    "   - **How to check**: Use Cook's distance or leverage plots to identify influential points.\n",
    "   - **How to fix**: Consider removing outliers or using robust regression techniques.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary:\n",
    "To ensure the validity of a linear regression model:\n",
    "- We have to check residual plots for linearity, homoscedasticity, and independence.\n",
    "- Use of statistical tests for normality and multicollinearity.\n",
    "- Addressing violations by transforming data, removing problematic variables, or using alternative regression methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. ***What is the difference between R-squared and Adjusted R-squared?***\n",
    "*Answer-*\n",
    "\n",
    "The primary difference between **R-squared** and **Adjusted R-squared** lies in how they account for the number of predictors in the regression model:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. R-squared:**\n",
    "- **Definition**: It measures the proportion of variance in the dependent variable that is explained by the independent variables in the model.\n",
    "- **Formula**: \n",
    "  \\[\n",
    "  R^2 = 1 - \\frac{\\text{Sum of Squared Residuals (SSR)}}{\\text{Total Sum of Squares (TSS)}}\n",
    "  \\]\n",
    "- **Key Properties**:\n",
    "  - Ranges from 0 to 1.\n",
    "  - Increases or stays the same when new predictors are added, regardless of their relevance.\n",
    "  - Cannot decrease, even if the new predictors are irrelevant.\n",
    "\n",
    "**Example**:\n",
    "- If \\( R^2 = 0.85 \\), it means 85% of the variance in the dependent variable is explained by the independent variables.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Adjusted R-squared:**\n",
    "- **Definition**: Adjusted R-squared modifies the R-squared value to account for the number of predictors in the model and penalizes the inclusion of irrelevant predictors.\n",
    "- **Formula**: \n",
    "  \\[\n",
    "  \\ {Adjusted} `R^2` = 1 - \\( \\frac{(1 - R^2)(n - 1)}/{n - k - 1} \\)\n",
    "  \\]\n",
    "  Where:\n",
    "  - \\( n \\): Number of observations.\n",
    "  - \\( k \\): Number of predictors.\n",
    "  - \\( R^2 \\): Regular R-squared value.\n",
    "  \n",
    "- **Key Properties**:\n",
    "  - Can decrease when adding predictors that do not improve the model.\n",
    "  - Provides a more accurate measure of model performance when comparing models with different numbers of predictors.\n",
    "\n",
    "**Example**:\n",
    "- If Adjusted \\( R^2 = 0.80 \\), it means that after adjusting for the number of predictors, the model explains 80% of the variance in the dependent variable.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Differences:**\n",
    "| **Aspect**             | **R-squared**                           | **Adjusted R-squared**                     |\n",
    "|-------------------------|-----------------------------------------|--------------------------------------------|\n",
    "| **Impact of Predictors**| Always increases or remains constant.   | Can increase or decrease depending on predictor relevance. |\n",
    "| **Penalty for Overfitting** | No penalty for adding irrelevant predictors. | Penalizes for irrelevant predictors by adjusting for model complexity. |\n",
    "| **Best Use Case**       | Evaluating model fit without considering complexity. | Comparing models with different numbers of predictors. |\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use Adjusted R-squared?**\n",
    "- When comparing models with different numbers of predictors to avoid overfitting.\n",
    "- When evaluating whether adding more predictors improves the model's explanatory power. \n",
    "\n",
    "### **Summary**:\n",
    "- **R-squared** focuses on explaining the variance in the dependent variable but may overestimate performance with more predictors.\n",
    "- **Adjusted R-squared** provides a more balanced evaluation by penalizing for irrelevant predictors, making it more reliable for model comparison."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. *** Why do we use Mean Squared Error (MSE)?***\n",
    "*Answer-*\n",
    "\n",
    "### Why Do We Use Mean Squared Error (MSE)?\n",
    "\n",
    "**Mean Squared Error (MSE)** is a widely used metric to evaluate the performance of regression models. It measures the average squared differences between predicted values (\\(\\hat{y}\\)) and actual values (\\(y\\)). Here's why it's used:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Mathematically Convenient**\n",
    "- MSE is defined as:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "  where:\n",
    "  - \\(y_i\\): Actual value of the dependent variable.\n",
    "  - \\(\\{y^}_i\\): Predicted value.\n",
    "  - \\(n\\): Number of data points.\n",
    "\n",
    "- Squaring the differences ensures that positive and negative errors don't cancel each other out, making MSE a true measure of error magnitude.\n",
    "- The differentiation of MSE (when optimizing parameters, e.g., in gradient descent) is smooth and continuous, which simplifies mathematical computation during model training.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Penalizes Larger Errors More**\n",
    "- Since the errors are squared, larger deviations between predictions and actual values have a disproportionate impact on the MSE.\n",
    "- This property makes MSE highly sensitive to significant errors, which is useful when large deviations are particularly undesirable.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Objective for Optimization**\n",
    "- Many machine learning algorithms, such as linear regression, neural networks, and gradient boosting, use MSE as the loss function to minimize during model training.\n",
    "- By minimizing MSE, the model learns to reduce prediction errors effectively.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Interpretability**\n",
    "- While the units of MSE are squared (making interpretation somewhat challenging), it provides a direct measure of the average squared error.\n",
    "- A lower MSE indicates better model performance, meaning that predictions are closer to the actual values on average.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Comparative Metric**\n",
    "- MSE can be used to compare the performance of multiple regression models on the same dataset. A model with a lower MSE is typically considered better in terms of prediction accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Limitations of Alternatives**\n",
    "- **Mean Absolute Error (MAE)**: Though simpler, MAE treats all errors equally (linear scale), which may not adequately emphasize large errors.\n",
    "- **Root Mean Squared Error (RMSE)**: While RMSE is on the same scale as the dependent variable, it inherits the same advantages as MSE but is computationally more expensive (due to the square root).\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Benefits:\n",
    "- **Computationally efficient**: Easy to calculate and optimize.\n",
    "- **Error sensitivity**: Highlights large errors effectively.\n",
    "- **Widely accepted**: Used as a standard metric in many regression tasks.\n",
    "\n",
    "However, MSE should be used cautiously in datasets with outliers, as its sensitivity to large errors may overly influence the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. ***What does an Adjusted R-squared value of 0.85 indicate?***\n",
    "*Answer-*\n",
    "\n",
    "An **Adjusted R-squared** value of **0.85** indicates that, after accounting for the number of predictors in the regression model, the model explains **85% of the variance** in the dependent variable.\n",
    "\n",
    "### Key Points to Understand:\n",
    "1. **Explanation of Variance**:\n",
    "   - Adjusted R-squared shows how well the independent variables collectively explain the variability in the dependent variable, considering the number of predictors.\n",
    "   - A value of 0.85 means the model is performing well, as 85% of the variability in the target variable is explained by the predictors.\n",
    "\n",
    "2. **Adjusted for Complexity**:\n",
    "   - Unlike regular \\( R^2 \\), Adjusted \\( R^2 \\) penalizes the model for adding unnecessary predictors that don't improve explanatory power.\n",
    "   - This means the model's performance is high even after accounting for irrelevant or redundant predictors.\n",
    "\n",
    "3. **Model Quality**:\n",
    "   - An Adjusted \\( R^2 \\) value close to 1 suggests a strong fit, while a value near 0 suggests a poor fit.\n",
    "   - With 0.85, the model fits the data well but isn't perfect. There might still be room for improvement or unexplained variability.\n",
    "\n",
    "4. **What It Doesn’t Indicate**:\n",
    "   - Adjusted \\( R^2 \\) does not guarantee the model is statistically valid. You still need to:\n",
    "     - Check residual plots for assumptions (e.g., linearity, homoscedasticity).\n",
    "     - Evaluate predictor significance (p-values).\n",
    "     - Ensure there is no multicollinearity.\n",
    "\n",
    "5. **Example**:\n",
    "   - If you're predicting house prices based on features like square footage, location, and number of bedrooms, an Adjusted \\( R^2 \\) of 0.85 means 85% of the variation in house prices is explained by the predictors included in the model.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion:\n",
    "An Adjusted R-squared value of 0.85 suggests that the regression model is robust, with most of the variance in the dependent variable being explained by the predictors. However, we should also assess the model's assumptions and other performance metrics to ensure it is reliable and interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. ***How do we check for normality of residuals in linear regression?***\n",
    "*Answer-*\n",
    "\n",
    "### How to Check for Normality of Residuals in Linear Regression?\n",
    "\n",
    "In linear regression, one of the assumptions is that the residuals (errors) follow a normal distribution. This is important for valid statistical inference, such as confidence intervals and hypothesis tests. Below are various methods to check for the normality of residuals:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Visual Methods**\n",
    "#### **a. Histogram of Residuals**\n",
    "- Plot a histogram of the residuals to see if they follow a bell-shaped curve.\n",
    "- **Interpretation**:\n",
    "  - A roughly symmetric, bell-shaped histogram suggests normality.\n",
    "  - Significant skewness or multimodality indicates non-normality.\n",
    "\n",
    "#### **b. Q-Q (Quantile-Quantile) Plot**\n",
    "- A Q-Q plot compares the quantiles of the residuals to a theoretical normal distribution.\n",
    "- **How to interpret**:\n",
    "  - If the points fall approximately along the diagonal line, the residuals are normally distributed.\n",
    "  - Deviations from the line (e.g., curves or s-shaped patterns) suggest non-normality.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Statistical Tests**\n",
    "#### **a. Shapiro-Wilk Test**\n",
    "- Tests the null hypothesis that the residuals are normally distributed.\n",
    "- **Interpretation**:\n",
    "  - p-value > 0.05: Fail to reject the null hypothesis; residuals are approximately normal.\n",
    "  - p-value ≤ 0.05: Reject the null hypothesis; residuals are not normal.\n",
    "\n",
    "#### **b. Kolmogorov-Smirnov (K-S) Test**\n",
    "- Compares the residuals to a normal distribution.\n",
    "- **Interpretation**:\n",
    "  - p-value > 0.05: Residuals are approximately normal.\n",
    "  - p-value ≤ 0.05: Residuals deviate from normality.\n",
    "\n",
    "#### **c. Anderson-Darling Test**\n",
    "- Measures how well the residuals fit a normal distribution.\n",
    "- **Interpretation**: A lower statistic suggests better normality.\n",
    "\n",
    "#### **d. Jarque-Bera Test**\n",
    "- Specifically tests for skewness and kurtosis in the residuals.\n",
    "- **Interpretation**:\n",
    "  - Low Jarque-Bera statistic and high p-value suggest normality.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Plot of Residuals**\n",
    "#### **a. Residual vs. Fitted Values**\n",
    "- While not directly about normality, plotting residuals against fitted values can reveal patterns that might indicate departures from normality.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Skewness and Kurtosis**\n",
    "- Calculate skewness and kurtosis of the residuals:\n",
    "  - **Skewness**: Should be close to 0 for a normal distribution.\n",
    "  - **Kurtosis**: Should be close to 3 for a normal distribution.\n",
    "\n",
    "---\n",
    "\n",
    "### **What If Residuals Are Not Normal?**\n",
    "1. **Transformations**:\n",
    "   - Apply transformations (e.g., log, square root) to the dependent variable or predictors to achieve normality.\n",
    "   \n",
    "2. **Robust Regression**:\n",
    "   - Use regression methods like quantile regression, which are less sensitive to non-normality.\n",
    "\n",
    "3. **Bootstrap Methods**:\n",
    "   - Use bootstrapping to estimate confidence intervals without relying on normality.\n",
    "\n",
    "4. **Consider the Impact**:\n",
    "   - For large datasets, the normality assumption becomes less critical due to the Central Limit Theorem.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary:\n",
    "- Use a combination of visual (histogram, Q-Q plot) and statistical methods (Shapiro-Wilk, Jarque-Bera) to check for normality.\n",
    "- If normality is violated, explore transformations, robust methods, or assess whether normality is essential for your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### **5. Use Statistical Libraries**\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import probplot\n",
    "\n",
    "# Example data for y_true and y_pred\n",
    "y_true = [3, -0.5, 2, 7]\n",
    "y_pred = [2.5, 0.0, 2, 8]\n",
    "\n",
    "# Calculate residuals\n",
    "residuals = [y_t - y_p for y_t, y_p in zip(y_true, y_pred)]\n",
    "\n",
    "# Histogram\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.show()\n",
    "\n",
    "# Q-Q Plot\n",
    "probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk Test: Statistic=0.993, p=0.972\n",
      "Jarque-Bera Test: Statistic=0.308, p=0.857\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro, jarque_bera\n",
    "\n",
    "# Shapiro-Wilk Test\n",
    "stat, p = shapiro(residuals)\n",
    "print('Shapiro-Wilk Test: Statistic=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "# Jarque-Bera Test\n",
    "stat, p = jarque_bera(residuals)\n",
    "print('Jarque-Bera Test: Statistic=%.3f, p=%.3f' % (stat, p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. ***What is multicollinearity, and how does it impact regression?***\n",
    "*Answer-*\n",
    "\n",
    "### **What is Multicollinearity?**\n",
    "\n",
    "**Multicollinearity** refers to a situation in regression analysis where two or more independent variables (predictors) are highly correlated. This means that one predictor can be linearly predicted from the others with a substantial degree of accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "### **Types of Multicollinearity**\n",
    "1. **Perfect Multicollinearity**:\n",
    "   - When one predictor is an exact linear combination of others (e.g., \\( X_3 = 2X_1 + 3X_2 \\)).\n",
    "   - This makes regression calculations impossible, as the matrix inversion in the model fails.\n",
    "\n",
    "2. **High (or Near-Perfect) Multicollinearity**:\n",
    "   - When predictors are highly correlated but not perfectly.\n",
    "   - While regression can still be performed, it leads to instability in the coefficient estimates.\n",
    "\n",
    "---\n",
    "\n",
    "### **How to Detect Multicollinearity**\n",
    "1. **Correlation Matrix**:\n",
    "   - Examine the pairwise correlations between predictors. A correlation coefficient (\\( r \\)) > 0.8 or < -0.8 may indicate multicollinearity.\n",
    "\n",
    "2. **Variance Inflation Factor (VIF)**:\n",
    "   - Measures how much the variance of a regression coefficient is inflated due to multicollinearity.\n",
    "   \n",
    "   - **Interpretation**:\n",
    "     - \\( VIF < 5 \\): Low multicollinearity (acceptable).\n",
    "     - \\( VIF > 10 \\): High multicollinearity (problematic).\n",
    "\n",
    "3. **Condition Number**:\n",
    "   - The ratio of the largest to the smallest singular value of the design matrix. A condition number > 30 suggests potential multicollinearity.\n",
    "\n",
    "4. **Eigenvalues**:\n",
    "   - Small eigenvalues of the correlation matrix indicate multicollinearity.\n",
    "\n",
    "---\n",
    "\n",
    "### **Impact of Multicollinearity on Regression**\n",
    "1. **Unstable Coefficients**:\n",
    "   - Coefficients of highly correlated predictors can become unstable, with large changes in magnitude or sign when minor changes occur in the data.\n",
    "\n",
    "2. **Loss of Interpretability**:\n",
    "   - It becomes difficult to determine the individual effect of each predictor on the dependent variable since they share overlapping information.\n",
    "\n",
    "3. **Inflated Standard Errors**:\n",
    "   - Multicollinearity increases the variance of coefficient estimates, leading to larger standard errors. This makes it harder to determine the statistical significance of predictors (high p-values).\n",
    "\n",
    "4. **Overfitting Risk**:\n",
    "   - Multicollinearity can increase the risk of overfitting, particularly when adding irrelevant predictors to the model.\n",
    "\n",
    "5. **Reduced Model Predictability**:\n",
    "   - While multicollinearity doesn’t directly affect predictions, it can weaken the model’s ability to generalize to new data, especially when the data changes.\n",
    "\n",
    "---\n",
    "\n",
    "### **How to Address Multicollinearity**\n",
    "1. **Remove Redundant Predictors**:\n",
    "   - Drop one or more highly correlated variables that do not add unique value to the model.\n",
    "\n",
    "2. **Combine Variables**:\n",
    "   - Use techniques like **Principal Component Analysis (PCA)** to create uncorrelated linear combinations of predictors.\n",
    "\n",
    "3. **Regularization Techniques**:\n",
    "   - Apply penalized regression methods such as:\n",
    "     - **Ridge Regression**: Reduces coefficient magnitudes by adding an \\( L_2 \\) penalty.\n",
    "     - **Lasso Regression**: Forces some coefficients to become zero using an \\( L_1 \\) penalty.\n",
    "\n",
    "4. **Centering Variables**:\n",
    "   - Center the predictors by subtracting their mean values to reduce multicollinearity caused by interactions.\n",
    "\n",
    "5. **Use Partial Least Squares (PLS)**:\n",
    "   - A regression method designed to deal with multicollinearity by projecting predictors to a lower-dimensional space.\n",
    "\n",
    "6. **Check Data Collection Process**:\n",
    "   - Ensure no unnecessary predictors are added and investigate potential reasons for high correlations in the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "- **Definition**: Multicollinearity occurs when predictors are highly correlated, leading to redundancy in the model.\n",
    "- **Impact**: It inflates standard errors, makes coefficients unstable, and reduces the interpretability of the regression model.\n",
    "- **Solution**: Address multicollinearity using techniques like removing redundant variables, applying PCA, or using regularization methods like Ridge or Lasso regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. ***What is Mean Absolute Error (MAE)?***\n",
    "*Answer-*\n",
    "\n",
    "### **What is Mean Absolute Error (MAE)?**\n",
    "\n",
    "**Mean Absolute Error (MAE)** is a common metric used to evaluate the accuracy of a regression model. It measures the average magnitude of the errors between predicted values (\\(\\{y^}\\)) and actual values (\\(y\\)), ignoring the direction of the errors.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Characteristics**\n",
    "1. **Absolute Errors**:\n",
    "   - By taking the absolute value of the errors, MAE ensures that positive and negative errors do not cancel each other out.\n",
    "   \n",
    "2. **Same Scale**:\n",
    "   - MAE has the same unit as the dependent variable, making it intuitive and easy to interpret.\n",
    "\n",
    "3. **Linear Measure**:\n",
    "   - MAE gives equal weight to all errors, making it less sensitive to outliers compared to metrics like Mean Squared Error (MSE).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Advantages of MAE**\n",
    "1. **Simple and Intuitive**:\n",
    "   - Easy to compute and interpret due to its straightforward formula.\n",
    "   \n",
    "2. **Robust to Outliers**:\n",
    "   - Unlike MSE, MAE does not disproportionately penalize large errors, making it more robust to outliers.\n",
    "\n",
    "3. **Direct Measure of Average Error**:\n",
    "   - MAE provides a direct interpretation of the average absolute difference between predictions and actual values.\n",
    "\n",
    "---\n",
    "\n",
    "### **Disadvantages of MAE**\n",
    "1. **Less Sensitive to Large Errors**:\n",
    "   - Because MAE does not square the errors, it underemphasizes larger deviations compared to metrics like MSE or RMSE.\n",
    "\n",
    "2. **Not Differentiable Everywhere**:\n",
    "   - The absolute value function used in MAE is not differentiable at zero, which can pose challenges during optimization in machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "### **Comparison with Other Metrics**\n",
    "- **MAE vs. MSE**:\n",
    "  - **MAE**: Penalizes all errors linearly. More robust to outliers.\n",
    "  - **MSE**: Penalizes large errors more (quadratic scale). More sensitive to outliers.\n",
    "  \n",
    "- **MAE vs. RMSE (Root Mean Squared Error)**:\n",
    "  - **MAE**: Easier to interpret; focuses on average absolute differences.\n",
    "  - **RMSE**: Gives greater weight to larger errors but has the same unit as the target variable.\n",
    "\n",
    "---\n",
    "\n",
    "### **Applications**\n",
    "1. **Model Evaluation**:\n",
    "   - Used to assess the accuracy of regression models in domains like finance, healthcare, and weather forecasting.\n",
    "   \n",
    "2. **Comparison of Models**:\n",
    "   - Helps compare the performance of different models on the same dataset.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "- **MAE** quantifies the average magnitude of errors in predictions.\n",
    "- It is simple to compute, robust to outliers, and provides a direct measure of prediction accuracy.\n",
    "- However, it may not highlight the impact of large errors as strongly as metrics like MSE or RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. ***What are the benefits of using an ML pipeline?***\n",
    "*Answer-*\n",
    "\n",
    "An **ML pipeline** is a sequence of data processing and modeling steps that automate the workflow of machine learning tasks, from data preprocessing to model training and evaluation. Pipelines bring efficiency, reproducibility, and scalability to ML projects.\n",
    "\n",
    "### **Key Benefits of ML Pipelines**:\n",
    "\n",
    "1. **Automation of Workflow**:\n",
    "-   Pipelines streamline the entire machine learning process by automating repetitive tasks like data preprocessing, feature engineering, and model training.\n",
    "-   This reduces manual intervention and accelerates development cycles.\n",
    "\n",
    "2. **Reproducibility**:\n",
    "-   By defining all steps in a pipeline, the workflow becomes consistent and reproducible.\n",
    "-   This is especially important when transitioning models from development to production or collaborating with multiple team members.\n",
    "\n",
    "3. **Modular Design**:\n",
    "-   ML pipelines are modular, enabling easy addition, removal, or replacement of components (e.g., swapping a feature engineering step or trying a different algorithm).\n",
    "-   This modularity fosters experimentation and makes it easier to debug specific stages of the pipeline.\n",
    "\n",
    "4. **Scalability**:\n",
    "-   Pipelines allow seamless scaling to large datasets or distributed systems by leveraging tools like Apache Spark or Kubernetes.\n",
    "-   They can handle data preprocessing and model training efficiently in a distributed or parallelized environment.\n",
    "\n",
    "5. **Ease of Hyperparameter Tuning**:\n",
    "-   Many ML pipeline frameworks support integration with hyperparameter tuning tools (e.g., grid search, random search, or Bayesian optimization).\n",
    "-   This makes it easier to optimize models systematically without modifying core pipeline steps.\n",
    "\n",
    "6. **Reduction of Errors**:\n",
    "-   Automation reduces human errors that can occur during repetitive tasks such as manual data preprocessing or feature engineering.\n",
    "-   Validation steps built into the pipeline ensure data consistency and correctness.\n",
    "\n",
    "7. **Code Reusability**:\n",
    "-   Pipelines encourage reusable code by encapsulating tasks in reusable components.\n",
    "-   This is particularly helpful when working on multiple projects or datasets with similar requirements.\n",
    "\n",
    "8. **Consistency Across Training and Inference**:\n",
    "-   A well-designed pipeline ensures that the same data preprocessing and feature engineering steps are applied during both training and inference.\n",
    "-   This eliminates discrepancies that could negatively affect model performance.\n",
    "\n",
    "9. **Improved Collaboration**:\n",
    "-   Pipelines provide a clear structure for the ML workflow, making it easier for team members to understand and collaborate on the project.\n",
    "-   Frameworks like MLflow or Kubeflow further enhance collaboration by tracking experiments and deployments.\n",
    "\n",
    "10. **Integration with Deployment**:\n",
    "-   Pipelines can be extended to include steps for model validation, packaging, and deployment, ensuring a smooth transition from development to production.\n",
    "-   Tools like CI/CD pipelines (e.g., Jenkins, GitHub Actions) can integrate with ML pipelines for automated deployment.\n",
    "\n",
    "11. **Support for Iterative Development**:\n",
    "-   Pipelines make it easier to iterate on models and workflows. \n",
    "For example:\n",
    "-   Update a preprocessing step and rerun the pipeline to assess its impact.\n",
    "-   Test multiple models or feature sets within the same pipeline structure.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example: Pipeline in Action**\n",
    "\n",
    "**Steps in an ML Pipeline:**\n",
    "\n",
    "1. *Data Preprocessing:*\n",
    "Handle missing values, scale features, and encode categorical variables.\n",
    "\n",
    "2. *Feature Engineering:*\n",
    "Generate or select important features.\n",
    "\n",
    "3. *Model Training:*\n",
    "Train the model on processed data.\n",
    "\n",
    "4. *Evaluation:*\n",
    "Assess model performance using validation metrics.\n",
    "\n",
    "5. *Deployment:*\n",
    "Deploy the model to production, ensuring the preprocessing steps are replicated.\n",
    "\n",
    "---\n",
    "\n",
    "### **Frameworks Supporting ML Pipelines**-\n",
    "\n",
    "1. **Scikit-learn:**\n",
    "-   Provides tools for building simple and efficient pipelines.\n",
    "\n",
    "2. **TensorFlow Extended (TFX):**\n",
    "-   Offers a complete ML pipeline for deep learning workflows.\n",
    "\n",
    "3. **Apache Airflow/Kubeflow:**\n",
    "-   Useful for orchestrating and deploying complex ML pipelines at scale.\n",
    "\n",
    "4. **MLflow:**\n",
    "-   Helps with tracking, packaging, and deploying pipeline components.\n",
    "\n",
    "5. **Azure ML/AWS Sagemaker:**\n",
    "-   Cloud platforms that provide end-to-end pipeline creation and management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n",
    "y = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define pipeline steps\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),    # Handle missing values\n",
    "    ('scaler', StandardScaler()),                  # Scale features\n",
    "    ('model', LinearRegression())                  # Train model\n",
    "])\n",
    "\n",
    "# Train pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. ***Why is RMSE considered more interpretable than MSE?***\n",
    "*Answer-*\n",
    "\n",
    "`Root Mean Squared Error (RMSE)` is considered more interpretable than Mean Squared Error (MSE) because:\n",
    "\n",
    "### 1. **Same Units as the Target Variable**\n",
    "   - **RMSE** is in the same units as the target variable, making it easier to understand and relate to the data. For example, if you're predicting house prices in dollars, RMSE will also be in dollars, making it intuitive to interpret how much error you can expect on average.\n",
    "   - **MSE**, on the other hand, is in squared units of the target variable (e.g., dollars squared), which is less intuitive and harder to interpret in practical terms.\n",
    "\n",
    "### 2. **Direct Comparison**\n",
    "   - With RMSE, you can directly compare the error magnitude to the range or standard deviation of the target variable, giving you a sense of how significant the error is.\n",
    "   - MSE's squared nature makes it harder to directly assess how far off predictions are from actual values.\n",
    "\n",
    "### 3. **Penalizing Large Errors**\n",
    "   - While both RMSE and MSE penalize large errors due to squaring, RMSE still maintains interpretability while reflecting the severity of large errors. This makes RMSE a better choice when you want to emphasize practical understanding alongside error penalties.\n",
    "\n",
    "### 4. **Widely Used in Practice**\n",
    "   - RMSE is more commonly reported in studies, papers, and industry practice because of its interpretability, making it easier to communicate results to stakeholders who might not have a strong statistical background.\n",
    "\n",
    "### Summary\n",
    "RMSE is favored over MSE for its interpretability because it provides error in the original unit of the target variable, making it easier to understand and relate to real-world scenarios. However, both metrics serve their purposes depending on the context—MSE is useful when emphasizing the impact of large errors, while RMSE balances interpretability with error sensitivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. ***What is pickling in Python, and how is it useful in ML?***\n",
    "*Answer-*\n",
    "\n",
    "**`Pickling`** is the process of serializing a Python object into a byte stream, allowing you to save the object to a file or transfer it over a network. Serialization converts the object into a format that can be stored or transmitted and later deserialized (unpickled) to restore the original object.\n",
    "\n",
    "In Python, the `pickle` module provides functions for this purpose:\n",
    "- **`pickle.dump()`**: Serializes an object and writes it to a file.\n",
    "- **`pickle.load()`**: Reads a serialized object from a file and reconstructs it.\n",
    "\n",
    "### How is Pickling Useful in Machine Learning?\n",
    "\n",
    "Pickling is particularly useful in ML for the following reasons:\n",
    "\n",
    "#### 1. **Saving Trained Models**\n",
    "   - Once a model is trained, you can serialize (pickle) it to save for future use. This avoids the need to retrain the model every time you need it.\n",
    "   - Example: Save a trained `scikit-learn` model using pickle:\n",
    "     ```python\n",
    "     import pickle\n",
    "     from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "     model = RandomForestClassifier()\n",
    "     model.fit(X_train, y_train)\n",
    "\n",
    "     with open('model.pkl', 'wb') as file:\n",
    "         pickle.dump(model, file)\n",
    "     ```\n",
    "\n",
    "#### 2. **Loading Pre-trained Models**\n",
    "   - You can load a saved model and use it directly for predictions without retraining.\n",
    "     ```python\n",
    "     with open('model.pkl', 'rb') as file:\n",
    "         loaded_model = pickle.load(file)\n",
    "     predictions = loaded_model.predict(X_test)\n",
    "     ```\n",
    "\n",
    "#### 3. **Storing Preprocessed Data**\n",
    "   - Intermediate data, such as cleaned datasets, preprocessed features, or embeddings, can be pickled and reused later in the pipeline to save time.\n",
    "\n",
    "#### 4. **Cross-Environment Sharing**\n",
    "   - Pickling enables sharing Python objects, like models or datasets, across different systems or environments without needing to regenerate or re-download the data.\n",
    "\n",
    "#### 5. **Checkpointing During Training**\n",
    "   - In long training processes, pickling can be used to periodically save the model state, allowing you to resume training from a specific checkpoint if interrupted.\n",
    "\n",
    "#### 6. **Caching**\n",
    "   - Pickling allows caching of intermediate results in ML pipelines, reducing computation time for repeated tasks.\n",
    "\n",
    "### Limitations of Pickling in ML\n",
    "While useful, pickling has some limitations:\n",
    "1. **Compatibility Issues**:\n",
    "   - Pickled files may not work across different Python versions or environments.\n",
    "2. **Security Risks**:\n",
    "   - Loading pickled files from untrusted sources can execute arbitrary code and pose security threats.\n",
    "3. **File Size**:\n",
    "   - Large models or datasets can result in large pickle files, which may be slow to serialize/deserialize.\n",
    "\n",
    "### Alternatives to Pickling in ML\n",
    "1. **Joblib**:\n",
    "   - Specialized for serializing large NumPy arrays and scikit-learn models, offering better performance.\n",
    "   - Example: \n",
    "     ```python\n",
    "     from joblib import dump, load\n",
    "     dump(model, 'model.joblib')\n",
    "     loaded_model = load('model.joblib')\n",
    "     ```\n",
    "\n",
    "2. **ONNX**:\n",
    "   - For sharing models across different ML frameworks (e.g., PyTorch, TensorFlow).\n",
    "   \n",
    "3. **JSON/CSV**:\n",
    "   - For saving simpler data structures (e.g., dictionaries, lists, or DataFrames).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. ***What does a high R-squared value mean?***\n",
    "*Answer-*\n",
    "\n",
    "**A high R-squared indicates that a large proportion of the variance in the dependent variable is explained by the independent variables. However, it doesn’t guarantee model quality or predictive power.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. ***What happens if linear regression assumptions are violated?***\n",
    "*Answer-*\n",
    "\n",
    "When the assumptions of linear regression are violated, the reliability, accuracy, and interpretability of the model's results can be compromised. Breakdown of the consequences based on the specific assumption violated:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Linearity**\n",
    "   **Assumption**: The relationship between the predictors (independent variables) and the target (dependent variable) is linear.\n",
    "\n",
    "   **Violation Consequences**:\n",
    "   - The model cannot accurately capture the true relationship.\n",
    "   - Predictions will be biased, and the model may perform poorly.\n",
    "   - \\(R^2\\) and coefficients may be misleading.\n",
    "   \n",
    "   **Solution**:\n",
    "   - Use of polynomial regression, splines, or other non-linear models.\n",
    "   - Perform feature engineering to better represent the relationship.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Independence of Errors**\n",
    "   **Assumption**: Residuals (errors) are independent of each other.\n",
    "\n",
    "   **Violation Consequences**:\n",
    "   - Typically occurs in time series data where residuals are autocorrelated.\n",
    "   - Results in underestimated or overestimated standard errors, leading to invalid hypothesis tests and confidence intervals.\n",
    "\n",
    "   **Solution**:\n",
    "   - Checking for autocorrelation using the Durbin-Watson test or residual plots.\n",
    "   - Using time series models like ARIMA or generalized least squares.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Homoscedasticity (Constant Variance of Errors)**\n",
    "   **Assumption**: The variance of the residuals is constant across all levels of the independent variables.\n",
    "\n",
    "   **Violation Consequences**:\n",
    "   - Leads to inefficient parameter estimates.\n",
    "   - Results in biased standard errors, making \\(t\\)-tests and \\(p\\)-values unreliable.\n",
    "   - This issue is also known as **heteroscedasticity**.\n",
    "\n",
    "   **Solution**:\n",
    "   - Use of weighted least squares (WLS) to address heteroscedasticity.\n",
    "   - Applying transformations (e.g., log or square root) to stabilize variance.\n",
    "   - Performing the Breusch-Pagan or White test to check for heteroscedasticity.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Normality of Errors**\n",
    "   **Assumption**: Residuals are normally distributed.\n",
    "\n",
    "   **Violation Consequences**:\n",
    "   - Impacts the validity of hypothesis tests, confidence intervals, and prediction intervals.\n",
    "   - Less of a problem with large datasets (thanks to the Central Limit Theorem).\n",
    "\n",
    "   **Solution**:\n",
    "   - Use of transformations (e.g., log, Box-Cox) to normalize the data.\n",
    "   - Non-parametric regression methods if normality is severely violated.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **No Multicollinearity**\n",
    "   **Assumption**: Predictors are not highly correlated with each other.\n",
    "\n",
    "   **Violation Consequences**:\n",
    "   - Coefficient estimates become unstable and sensitive to small changes in the data.\n",
    "   - Difficulty in interpreting the individual effect of predictors.\n",
    "   - Inflated standard errors lead to unreliable significance tests.\n",
    "\n",
    "   **Solution**:\n",
    "   - Computing the Variance Inflation Factor (VIF); if VIF > 10, multicollinearity is a concern.\n",
    "   - Removing or combining highly correlated variables.\n",
    "   - Use of regularization techniques like Ridge or Lasso regression.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **No Omitted Variable Bias**\n",
    "   **Assumption**: The model includes all relevant variables that influence the dependent variable.\n",
    "\n",
    "   **Violation Consequences**:\n",
    "   - Missing variables can lead to biased coefficient estimates for included predictors.\n",
    "   - Reduces the accuracy of predictions and interpretability.\n",
    "\n",
    "   **Solution**:\n",
    "   - Analyzing the problem domain to ensure all key predictors are included.\n",
    "   - Using feature selection techniques to identify missing variables.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Error Independence from Predictors**\n",
    "   **Assumption**: Residuals are not correlated with the independent variables.\n",
    "\n",
    "   **Violation Consequences**:\n",
    "   - Indicates model misspecification, such as missing interaction terms or non-linear relationships.\n",
    "   - Results in biased coefficient estimates.\n",
    "\n",
    "   **Solution**:\n",
    "   - Including interaction terms or polynomial terms if needed.\n",
    "   - Performing residual analysis to identify patterns.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Impacts\n",
    "Violating these assumptions can result in:\n",
    "1. **Biased or inefficient parameter estimates**.\n",
    "2. **Misleading hypothesis tests and confidence intervals**.\n",
    "3. **Poor model performance and predictions**.\n",
    "\n",
    "Understanding the assumptions and performing diagnostic tests (e.g., residual plots, VIF checks, normality tests) is crucial to ensure the validity of regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. ***How can we address multicollinearity in regression?***\n",
    "*Answer-*\n",
    "\n",
    "Addressing multicollinearity in regression is essential because it can make coefficient estimates unstable, inflate standard errors, and reduce the interpretability of the model. Below are various strategies to handle multicollinearity effectively:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Remove Highly Correlated Predictors**\n",
    "   - Identify predictors with high correlations (using a correlation matrix or heatmap) and remove one of the correlated variables.\n",
    "   - **Steps**:\n",
    "     - Calculate pairwise correlations among predictors.\n",
    "     - Drop variables with the highest correlation values (\\(|r| > 0.8\\) is a common threshold).\n",
    "   - **Tools**:\n",
    "     ```python\n",
    "     import pandas as pd\n",
    "     corr_matrix = df.corr()\n",
    "     print(corr_matrix)\n",
    "     ```\n",
    "   - **Pro**: Simplifies the model.\n",
    "   - **Con**: Risk of losing potentially valuable information.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Use Variance Inflation Factor (VIF)**\n",
    "   - Calculate the **Variance Inflation Factor (VIF)** to measure how much a predictor is explained by other predictors.\n",
    "   - Drop variables with high VIF values (\\( \\text{VIF} > 10 \\) is a common threshold).\n",
    "   - **Steps**:\n",
    "     ```python\n",
    "     from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "     from statsmodels.tools.tools import add_constant\n",
    "\n",
    "     X = add_constant(df)  # Add intercept term\n",
    "     vif_data = pd.DataFrame()\n",
    "     vif_data[\"feature\"] = X.columns\n",
    "     vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "     print(vif_data)\n",
    "     ```\n",
    "   - **Pro**: Targets the variables causing the issue.\n",
    "   - **Con**: May still lead to losing useful predictors.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Combine Predictors**\n",
    "   - Combine correlated variables into a single feature using **Principal Component Analysis (PCA)** or **Feature Engineering**.\n",
    "   - **Steps**:\n",
    "     - Use PCA to reduce dimensionality while retaining most of the variance.\n",
    "     ```python\n",
    "     from sklearn.decomposition import PCA\n",
    "\n",
    "     pca = PCA(n_components=2)  # Keep 2 principal components\n",
    "     X_pca = pca.fit_transform(df)\n",
    "     ```\n",
    "   - **Pro**: Retains most of the information in a reduced form.\n",
    "   - **Con**: Makes interpretability more challenging.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Regularization**\n",
    "   - Use regularization techniques like **Ridge Regression** (L2 regularization) or **Lasso Regression** (L1 regularization) to penalize large coefficients and reduce multicollinearity's impact.\n",
    "   - **Steps**:\n",
    "     ```python\n",
    "     from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "     ridge = Ridge(alpha=1.0)  # L2 penalty\n",
    "     ridge.fit(X_train, y_train)\n",
    "\n",
    "     lasso = Lasso(alpha=0.01)  # L1 penalty\n",
    "     lasso.fit(X_train, y_train)\n",
    "     ```\n",
    "   - **Pro**: Keeps all variables while controlling multicollinearity.\n",
    "   - **Con**: Introduces bias in coefficient estimates.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Centering or Scaling the Data**\n",
    "   - Standardize predictors to make them comparable and reduce multicollinearity caused by differences in magnitude.\n",
    "   - **Steps**:\n",
    "     ```python\n",
    "     from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "     scaler = StandardScaler()\n",
    "     X_scaled = scaler.fit_transform(X)\n",
    "     ```\n",
    "   - **Pro**: Useful for models sensitive to scaling (e.g., regularization).\n",
    "   - **Con**: Does not eliminate multicollinearity entirely.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Domain Knowledge-Based Selection**\n",
    "   - Use your understanding of the domain to prioritize the most meaningful variables and drop less relevant ones.\n",
    "   - **Pro**: Helps focus on variables with the most predictive power.\n",
    "   - **Con**: Requires expert knowledge and might exclude statistically useful variables.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Use Partial Least Squares (PLS) Regression**\n",
    "   - PLS regression reduces predictors into uncorrelated components while maximizing their relationship with the target variable.\n",
    "   - **Steps**:\n",
    "     ```python\n",
    "     from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "     pls = PLSRegression(n_components=2)\n",
    "     pls.fit(X_train, y_train)\n",
    "     ```\n",
    "   - **Pro**: Combines feature reduction and predictive modeling.\n",
    "   - **Con**: Reduced interpretability of components.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Increase Sample Size**\n",
    "   - Multicollinearity is often worsened in small datasets. Adding more samples can reduce its impact by improving the stability of coefficient estimates.\n",
    "   - **Pro**: Improves overall model performance.\n",
    "   - **Con**: May not always be feasible.\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Use Statistical Methods to Test for Multicollinearity**\n",
    "   - Test for multicollinearity using tools like eigenvalues or condition numbers from the covariance matrix.\n",
    "   - Address highly collinear variables by modifying the design matrix or removing variables based on test results.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Approaches:\n",
    "| **Method**                  | **Pros**                                      | **Cons**                                       |\n",
    "|-----------------------------|-----------------------------------------------|-----------------------------------------------|\n",
    "| Remove Variables            | Simple and intuitive                         | Risk of losing important predictors           |\n",
    "| VIF                        | Targets problematic predictors               | May still drop useful variables               |\n",
    "| PCA/Feature Engineering     | Retains most information                     | Reduces interpretability                      |\n",
    "| Regularization              | Keeps all variables                          | Introduces bias in coefficients               |\n",
    "| Scaling                     | Improves numerical stability                 | Doesn't eliminate multicollinearity           |\n",
    "| Domain Knowledge            | Adds practical relevance                     | Relies on expertise                           |\n",
    "| PLS Regression              | Combines reduction and prediction            | Harder to interpret                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. ***How can feature selection improve model performance in regression analysis?***\n",
    "*Answer-*\n",
    "\n",
    "**`Feature selection`** is the process of identifying and retaining the most relevant features (predictors) for building a regression model. By selecting the right features, feature selection can improve model performance in several ways:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Reduces Overfitting**\n",
    "   - **Problem**: Including irrelevant or redundant features increases the risk of overfitting, especially in small datasets.\n",
    "   - **How Feature Selection Helps**:\n",
    "     - Removing unnecessary features reduces noise and ensures the model generalizes better to unseen data.\n",
    "     - By focusing only on relevant variables, the model captures meaningful relationships instead of spurious ones.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Improves Model Interpretability**\n",
    "   - **Problem**: A model with too many predictors can be hard to interpret, especially if there are irrelevant features or multicollinearity.\n",
    "   - **How Feature Selection Helps**:\n",
    "     - By keeping only the most important predictors, the model becomes easier to explain and analyze.\n",
    "     - For example, in a house price prediction model, selecting features like size and location is more interpretable than including dozens of less relevant predictors.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Enhances Computational Efficiency**\n",
    "   - **Problem**: High-dimensional datasets increase computational cost during model training and inference.\n",
    "   - **How Feature Selection Helps**:\n",
    "     - Reducing the number of features decreases the size of the dataset, speeding up training and prediction.\n",
    "     - Essential for large datasets or real-time applications.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Improves Model Accuracy**\n",
    "   - **Problem**: Irrelevant or highly correlated features can dilute the signal and lead to suboptimal performance.\n",
    "   - **How Feature Selection Helps**:\n",
    "     - By focusing on the most predictive features, the model produces more accurate predictions.\n",
    "     - Removes multicollinearity, which can destabilize coefficient estimates in regression.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Prevents the Curse of Dimensionality**\n",
    "   - **Problem**: High-dimensional datasets can cause sparsity, making it harder for models to learn patterns effectively.\n",
    "   - **How Feature Selection Helps**:\n",
    "     - Reducing dimensions mitigates the curse of dimensionality and helps the model focus on key patterns.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Reduces Multicollinearity**\n",
    "   - **Problem**: Highly correlated features can make regression coefficients unstable and difficult to interpret.\n",
    "   - **How Feature Selection Helps**:\n",
    "     - Removing redundant predictors minimizes multicollinearity and improves the reliability of coefficient estimates.\n",
    "\n",
    "---\n",
    "\n",
    "### **Feature Selection Techniques**\n",
    "\n",
    "#### **1. Filter Methods**\n",
    "   - Select features based on statistical criteria (independent of the model).\n",
    "   - Examples:\n",
    "     - Correlation: Keep features with high correlation to the target but low inter-correlation.\n",
    "     - Statistical tests: Use methods like ANOVA, chi-squared tests, or mutual information.\n",
    "   - **Pro**: Fast and simple.\n",
    "   - **Con**: Ignores feature interactions.\n",
    "\n",
    "#### **2. Wrapper Methods**\n",
    "   - Use a model to evaluate subsets of features and select the best-performing ones.\n",
    "   - Examples:\n",
    "     - **Recursive Feature Elimination (RFE)**: Iteratively removes the least important features.\n",
    "     - **Forward Selection**: Starts with no features and adds them one by one.\n",
    "     - **Backward Elimination**: Starts with all features and removes them one by one.\n",
    "   - **Pro**: Accounts for feature interactions.\n",
    "   - **Con**: Computationally expensive.\n",
    "\n",
    "#### **3. Embedded Methods**\n",
    "   - Feature selection is built into the model training process.\n",
    "   - Examples:\n",
    "     - **Lasso Regression (L1 Regularization)**: Shrinks some coefficients to zero, effectively removing features.\n",
    "     - **Tree-based models**: Feature importance rankings from models like Random Forests or Gradient Boosting.\n",
    "   - **Pro**: Efficient and model-specific.\n",
    "   - **Con**: May not generalize across different models.\n",
    "\n",
    "---\n",
    "\n",
    "### **When Should You Use Feature Selection?**\n",
    "- **Small Datasets**: To avoid overfitting and improve generalization.\n",
    "- **High-Dimensional Datasets**: To reduce complexity and computation time.\n",
    "- **Multicollinearity Issues**: To stabilize the regression coefficients.\n",
    "- **Interpretability**: When the goal is to clearly understand the impact of individual predictors.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True]\n",
      "[1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:300: UserWarning: Found n_features_to_select=5 > n_features=2. There will be no feature selection and all features will be kept.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initialize model and RFE\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=5)\n",
    "X_rfe = rfe.fit_transform(X, y)\n",
    "\n",
    "# Features selected\n",
    "print(rfe.support_)  # True/False for selected features\n",
    "print(rfe.ranking_)  # Feature ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Fit Lasso model\n",
    "lasso = Lasso(alpha=0.01).fit(X, y)\n",
    "\n",
    "# Select important features\n",
    "sfm = SelectFromModel(lasso, prefit=True)\n",
    "X_selected = sfm.transform(X)\n",
    "print(sfm.get_support())  # True/False for selected features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. ***How is Adjusted R-squared calculated?***\n",
    "*Answer-*\n",
    "\n",
    "**`Adjusted R-squared`** = 1 - [(1 - R²) × (n - 1) / (n - k - 1)]\n",
    "Where:\n",
    "\n",
    "-   n = number of observations.\n",
    "\n",
    "-   k = number of predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. ***Why is MSE sensitive to outliers?***\n",
    "*Answer-*\n",
    "\n",
    "MSE squares the errors, magnifying the impact of larger errors (outliers) compared to smaller ones, making it sensitive to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. ***What is the role of homoscedasticity in linear regression?***\n",
    "*Answer-*\n",
    "\n",
    "### **The Role of Homoscedasticity in Linear Regression**\n",
    "\n",
    "**Homoscedasticity** refers to the condition in which the variance of the residuals (errors) is constant across all levels of the independent variables in a regression model. This is a key assumption in linear regression, and its presence is crucial for making valid statistical inferences about the model.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why Homoscedasticity is Important**\n",
    "1. **Ensures Validity of Inference:**\n",
    "   - Linear regression relies on the assumption of homoscedasticity for calculating confidence intervals, p-values, and hypothesis tests.\n",
    "   - If the errors are homoscedastic, the estimated regression coefficients are unbiased and efficient.\n",
    "\n",
    "2. **Minimizes Bias in Standard Errors:**\n",
    "   - In the presence of **heteroscedasticity** (when error variances are not constant), the standard errors of the coefficients may be biased.\n",
    "   - This can lead to:\n",
    "     - Incorrectly rejecting or failing to reject hypotheses in statistical tests.\n",
    "     - Over- or underestimating the significance of predictors.\n",
    "\n",
    "3. **Supports Best Linear Unbiased Estimators (BLUE):**\n",
    "   - Homoscedasticity, along with other assumptions, ensures that the Ordinary Least Squares (OLS) estimators are **BLUE**:\n",
    "     - Best (minimum variance)\n",
    "     - Linear\n",
    "     - Unbiased\n",
    "\n",
    "4. **Maintains Predictive Performance:**\n",
    "   - Homoscedastic errors lead to stable predictions across the range of independent variables.\n",
    "   - In contrast, heteroscedastic errors can result in models that perform poorly on observations where the variance is high.\n",
    "\n",
    "---\n",
    "\n",
    "### **Impact of Violating Homoscedasticity**\n",
    "When homoscedasticity is violated (i.e., heteroscedasticity exists):\n",
    "1. **Inefficient Estimates**:\n",
    "   - The OLS estimates remain unbiased but are no longer efficient, meaning they do not have the minimum variance among linear estimators.\n",
    "\n",
    "2. **Invalid Hypothesis Tests**:\n",
    "   - Confidence intervals and p-values for regression coefficients may be invalid, leading to incorrect conclusions about the significance of predictors.\n",
    "\n",
    "3. **Unreliable Predictions**:\n",
    "   - Predictions may be less accurate, particularly in regions where the variance of errors is high.\n",
    "\n",
    "---\n",
    "\n",
    "### **Detecting Homoscedasticity**\n",
    "Homoscedasticity can be assessed through several diagnostic techniques:\n",
    "\n",
    "1. **Residual Plots**:\n",
    "   - Plot residuals (\\( y - \\hat{y} \\)) against fitted values (\\( \\hat{y} \\)) or predictors.\n",
    "   - Homoscedasticity: Residuals are randomly scattered with no visible pattern.\n",
    "   - Heteroscedasticity: Residuals show patterns, such as a funnel shape (narrow at one end, wide at the other).\n",
    "\n",
    "2. **Statistical Tests**:\n",
    "   - **Breusch-Pagan Test**:\n",
    "     - Tests whether the variance of residuals depends on the independent variables.\n",
    "   - **White Test**:\n",
    "     - A more general test for heteroscedasticity.\n",
    "   - **Goldfeld-Quandt Test**:\n",
    "     - Compares variances in different parts of the dataset to detect heteroscedasticity.\n",
    "\n",
    "3. **Variance Trend Analysis**:\n",
    "   - Compute and visually inspect the variance of residuals across different subsets of the data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Addressing Heteroscedasticity**\n",
    "If heteroscedasticity is detected, several strategies can be used to address it:\n",
    "\n",
    "#### **1. Transforming the Dependent Variable**\n",
    "   - Apply transformations like log, square root, or Box-Cox transformations to stabilize variance.\n",
    "   - Example: If error variance grows with \\( y \\), take \\( \\log(y) \\) to reduce the impact of large values.\n",
    "\n",
    "#### **2. Weighted Least Squares (WLS)**\n",
    "   - Assign weights to observations based on their variances to give less importance to observations with higher error variance.\n",
    "\n",
    "#### **3. Robust Standard Errors**\n",
    "   - Use heteroscedasticity-robust standard errors (e.g., **Huber-White sandwich estimators**) to make valid statistical inferences even when heteroscedasticity is present.\n",
    "\n",
    "#### **4. Adding Missing Predictors**\n",
    "   - Check if important variables that affect error variance are missing from the model. Adding these predictors can reduce heteroscedasticity.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "Homoscedasticity ensures the validity of statistical inferences and efficient regression estimates. If violated, the reliability of the model decreases, but techniques like transformations, weighted least squares, or robust standard errors can address the issue effectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from X and y\n",
    "data = pd.DataFrame(X, columns=['feature1', 'feature2'])\n",
    "data['target'] = y\n",
    "\n",
    "X = data[['feature1']]\n",
    "y = data['target']\n",
    "\n",
    "# Fit linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Residual plot\n",
    "residuals = y - y_pred\n",
    "plt.scatter(y_pred, residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lagrange multiplier statistic: 4.224137931034482\n",
      "p-value: 0.039852859099183686\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.api import OLS, add_constant\n",
    "\n",
    "# Fit OLS model\n",
    "X_const = add_constant(X)\n",
    "ols_model = OLS(y, X_const).fit()\n",
    "\n",
    "# Breusch-Pagan test\n",
    "bp_test = het_breuschpagan(ols_model.resid, X_const)\n",
    "print(\"Lagrange multiplier statistic:\", bp_test[0])\n",
    "print(\"p-value:\", bp_test[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. ***What is Root Mean Squared Error (RMSE)?***\n",
    "*Answer-*\n",
    "\n",
    "**Root Mean Squared Error (RMSE)** is a widely used metric for evaluating the performance of a regression model. It measures the average magnitude of the errors between predicted values and actual values, with a focus on penalizing large errors due to the squaring of the residuals.\n",
    "\n",
    "\n",
    "### **How RMSE Works**:\n",
    "\n",
    "1. **Residuals:**\n",
    "\n",
    "-   RMSE calculates the residuals, which are the differences between actual values(𝑦𝑖) and predicted values (𝑦^𝑖).\n",
    "\n",
    "2. **Squaring the Residuals:**\n",
    "\n",
    "-   Squaring each residual ensures that negative and positive errors are treated equally and that larger errors are penalized more than smaller ones.\n",
    "\n",
    "3. **Averaging:**\n",
    "\n",
    "-   After squaring, the average of the squared residuals is taken. This provides a single number that summarizes the overall error.\n",
    "\n",
    "4. **Taking the Square Root:**\n",
    "\n",
    "-   The square root is taken to bring the scale of the error back to the same units as the original data (unlike MSE, which has squared units).\n",
    "\n",
    "---\n",
    "\n",
    "### **Why RMSE is Useful?**\n",
    "\n",
    "1. **Interpretability:**\n",
    "\n",
    "-   Since RMSE is in the same units as the target variable, it’s easy to interpret in the context of the problem. For example, if you're predicting house prices, an RMSE of 10,000 means the average error in your predictions is $10,000.\n",
    "\n",
    "2. **Sensitive to Large Errors:**\n",
    "-   The squaring of errors means RMSE heavily penalizes large errors, making it useful when you want to reduce large deviations between predicted and actual values.\n",
    "\n",
    "3. **Comparing Models:**\n",
    "\n",
    "-   RMSE is often used to compare different models. Lower RMSE indicates a better model fit (though it's important to compare models on similar datasets and conditions).\n",
    "\n",
    "---\n",
    "\n",
    "### **Advantages of RMSE**-\n",
    "\n",
    "1. **Clear Interpretation:**\n",
    "\n",
    "-   It is in the same units as the original data, making it easier to understand and compare.\n",
    "\n",
    "2. **Penalizes Larger Errors:**\n",
    "-   RMSE penalizes larger errors more than smaller ones, making it useful when large errors are undesirable.\n",
    "\n",
    "3. **Widely Used:**\n",
    "-   It is a standard metric in regression problems, allowing easy comparisons across different models.\n",
    "\n",
    "### **Disadvantages of RMSE**-\n",
    "\n",
    "1. **Sensitive to Outliers:**\n",
    "\n",
    "-   Due to the squaring of residuals, RMSE is highly sensitive to outliers. A few large errors can result in a significantly higher RMSE, which may not reflect the overall model's performance if most errors are small.\n",
    "\n",
    "2. **Not a Relative Measure:**\n",
    "\n",
    "-   RMSE does not provide a sense of the model’s error relative to the scale of the data (e.g., in percentage terms). A model could have a small RMSE but still perform poorly if the target variable has a wide range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. ***Why is pickling considered risky?***\n",
    "*Answer-*\n",
    "\n",
    "Pickling in Python is the process of serializing and deserializing Python objects to and from byte streams. While it’s a powerful tool for saving and loading data structures, it can pose several risks, particularly when dealing with untrusted data sources.\n",
    "\n",
    "### **Risks of Pickling**\n",
    "\n",
    "1. **Security Vulnerabilities**:\n",
    "   - **Code Execution**: Pickling can execute arbitrary code when loading (unpickling) data. If you load data that was pickled by an untrusted source, it might contain malicious code embedded in the object that can be executed during unpickling.\n",
    "   - This happens because `pickle` can serialize not just data but also functions, classes, and code objects. Therefore, loading an object that contains malicious code can compromise the security of your application.\n",
    "   \n",
    "   For example:\n",
    "   ```python\n",
    "   import pickle\n",
    "   \n",
    "   # Untrusted data (from malicious source)\n",
    "   malicious_data = b\"...\"  # Some malicious pickle byte stream\n",
    "   \n",
    "   # Unpickling this data could execute harmful code\n",
    "   pickle.loads(malicious_data)\n",
    "   ```\n",
    "\n",
    "2. **Unintended Data Integrity Issues**:\n",
    "   - If the data being unpickled has been tampered with or corrupted, it can lead to unpredictable behavior, crashes, or loss of integrity in the program. Pickle doesn’t provide built-in integrity checks like cryptographic signatures, so it’s difficult to verify that the data hasn’t been altered or corrupted.\n",
    "\n",
    "3. **Incompatibility Across Python Versions**:\n",
    "   - Pickled data is often version-dependent. If you pickle an object in one version of Python and try to unpickle it in a different version, it might not work, especially when Python's internal object representation changes between versions. This makes pickled data less portable than other formats like JSON or CSV.\n",
    "   - For example, classes, modules, and their structures might change, causing issues when attempting to unpickle data serialized with a different Python version.\n",
    "\n",
    "4. **Limited Interoperability**:\n",
    "   - Pickle is Python-specific. It’s not a good choice if you need your data to be shared across different languages or platforms. Formats like JSON or XML are much more interoperable, as they are human-readable and can be parsed by multiple programming languages.\n",
    "   - Therefore, if you want to share data across different systems or with other languages, you would avoid pickle and prefer more standard formats.\n",
    "\n",
    "5. **Risk of Pickling Arbitrary Objects**:\n",
    "   - Not all Python objects can be safely pickled. For instance, file handlers, network connections, or database connections cannot always be properly serialized with pickle. Attempting to pickle objects that involve external resources or states can lead to errors or incomplete data being stored.\n",
    "   - Pickle may also serialize parts of the environment (such as global variables or references to functions), which can be problematic if the context changes or the function no longer exists.\n",
    "\n",
    "---\n",
    "\n",
    "### **How to Mitigate the Risks**\n",
    "\n",
    "1. **Avoid Unpickling Untrusted Data**:\n",
    "   - Only unpickle data from trusted sources. Never load pickle data from untrusted or external sources, as they may contain malicious code.\n",
    "\n",
    "2. **Use Secure Alternatives**:\n",
    "   - If security is a concern, consider using other serialization methods that are more secure, such as **JSON** or **MessagePack**. These formats do not execute code during deserialization and are generally safer.\n",
    "   - For example, JSON is text-based, human-readable, and can be used across different programming languages:\n",
    "   ```python\n",
    "   import json\n",
    "\n",
    "   # Safe to use, as JSON only supports basic types like numbers, strings, lists, and dictionaries\n",
    "   data = {\"name\": \"Alice\", \"age\": 30}\n",
    "   with open(\"data.json\", \"w\") as f:\n",
    "       json.dump(data, f)\n",
    "   ```\n",
    "\n",
    "3. **Use `pickle` with Caution**:\n",
    "   - If you must use `pickle`, ensure that the data being unpickled is from a trusted source.\n",
    "   - You can restrict the types of objects that can be pickled using the `pickle.load` function by using `pickle.Unpickler` and limiting the set of allowed classes.\n",
    "   - Example:\n",
    "   ```python\n",
    "   import pickle\n",
    "\n",
    "   # Custom unpickler that only allows certain classes to be loaded\n",
    "   class SafeUnpickler(pickle.Unpickler):\n",
    "       def find_class(self, module, name):\n",
    "           if name in ['allowed_module.Class1', 'allowed_module.Class2']:\n",
    "               return super().find_class(module, name)\n",
    "           raise pickle.UnpicklingError(f\"Unsafe class: {name}\")\n",
    "\n",
    "   # Load with the safe unpickler\n",
    "   with open('data.pkl', 'rb') as f:\n",
    "       safe_unpickler = SafeUnpickler(f)\n",
    "       data = safe_unpickler.load()\n",
    "   ```\n",
    "\n",
    "4. **Use HMAC or Cryptography for Data Integrity**:\n",
    "   - If you need to ensure data integrity, consider using HMAC (Hash-based Message Authentication Code) or cryptographic techniques to verify the authenticity of pickled data before unpickling it.\n",
    "\n",
    "5. **Version Control for Compatibility**:\n",
    "   - For long-term storage, use version control when pickling data. This includes adding checks for version compatibility or using a version-specific schema when pickling and unpickling objects.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary**\n",
    "\n",
    "Pickling in Python is a powerful tool for object serialization, but it comes with security risks, especially when dealing with untrusted data sources. The main concerns are:\n",
    "- **Security**: Arbitrary code execution during unpickling.\n",
    "- **Data Integrity**: Difficulty in ensuring data hasn't been tampered with.\n",
    "- **Version Compatibility**: Pickle can be Python-version-dependent and may cause compatibility issues.\n",
    "- **Interoperability**: Pickle is Python-specific and does not work well across different languages or platforms.\n",
    "\n",
    "To mitigate these risks, avoid unpickling untrusted data, use safer alternatives like JSON when possible, and take extra precautions when working with pickle in trusted environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. ***What alternatives exist to pickling for saving ML models?***\n",
    "*Answer-*\n",
    "\n",
    "There are several alternatives to pickling for saving machine learning models that are more secure, robust, and interoperable. These methods are particularly useful for production environments, long-term storage, or sharing models across systems. Here's a breakdown of the popular alternatives:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Joblib**\n",
    "**Joblib** is a Python library specifically designed for serializing objects, particularly large numerical arrays or machine learning models.\n",
    "\n",
    "- **Advantages**:\n",
    "  - Optimized for storing large numpy arrays, which are commonly used in ML models.\n",
    "  - Faster and more efficient than pickle for models with large datasets (e.g., trained scikit-learn models).\n",
    "  - Safer than pickle but still requires caution when loading data from untrusted sources.\n",
    "\n",
    "- **Example**:\n",
    "```python\n",
    "from joblib import dump, load\n",
    "\n",
    "# Save the model\n",
    "dump(model, 'model.joblib')\n",
    "\n",
    "# Load the model\n",
    "model = load('model.joblib')\n",
    "```\n",
    "\n",
    "- **Use Case**:\n",
    "  - When working with scikit-learn models or large numerical data.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. ONNX (Open Neural Network Exchange)**\n",
    "**ONNX** is an open-standard format for representing machine learning models. It supports interoperability across different frameworks like TensorFlow, PyTorch, and scikit-learn.\n",
    "\n",
    "- **Advantages**:\n",
    "  - Framework-agnostic: Allows you to train a model in one framework and use it in another.\n",
    "  - Optimized for deployment across various platforms and hardware (e.g., GPUs, edge devices).\n",
    "  - Secure and standardized format.\n",
    "\n",
    "- **Example**:\n",
    "```python\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import torch\n",
    "\n",
    "# Save the model\n",
    "torch.onnx.export(model, dummy_input, \"model.onnx\")\n",
    "\n",
    "# Load the model\n",
    "onnx_model = onnx.load(\"model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "```\n",
    "\n",
    "- **Use Case**:\n",
    "  - When you need cross-framework or cross-platform compatibility, or when deploying models to production environments.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. TensorFlow SavedModel Format**\n",
    "For TensorFlow and Keras models, the **SavedModel** format is the recommended way to save models. It preserves the entire model, including its architecture, weights, and optimizer state.\n",
    "\n",
    "- **Advantages**:\n",
    "  - Framework-specific but highly robust for TensorFlow/Keras models.\n",
    "  - Supports reloading for both training and inference.\n",
    "  - Compatible with TensorFlow Serving for production deployments.\n",
    "\n",
    "- **Example**:\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Save the model\n",
    "model.save('saved_model/my_model')\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('saved_model/my_model')\n",
    "```\n",
    "\n",
    "- **Use Case**:\n",
    "  - TensorFlow/Keras workflows, particularly in production or deployment scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. PyTorch Serialization**\n",
    "PyTorch provides its own serialization methods using **torch.save** and **torch.load**.\n",
    "\n",
    "- **Advantages**:\n",
    "  - Saves the model weights (`state_dict`) and architecture separately, making it flexible.\n",
    "  - Recommended for saving PyTorch models.\n",
    "\n",
    "- **Example**:\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Load the model\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()\n",
    "```\n",
    "\n",
    "- **Use Case**:\n",
    "  - PyTorch-specific workflows.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. JSON**\n",
    "JSON is a lightweight and human-readable format for saving model metadata (e.g., architecture or hyperparameters) but is less suitable for saving numerical weights.\n",
    "\n",
    "- **Advantages**:\n",
    "  - Highly portable and interoperable across languages and platforms.\n",
    "  - Secure because JSON does not allow execution of arbitrary code.\n",
    "\n",
    "- **Example**:\n",
    "```python\n",
    "import json\n",
    "\n",
    "# Save model parameters\n",
    "model_params = {\"learning_rate\": 0.01, \"epochs\": 10}\n",
    "with open('model.json', 'w') as f:\n",
    "    json.dump(model_params, f)\n",
    "\n",
    "# Load model parameters\n",
    "with open('model.json', 'r') as f:\n",
    "    model_params = json.load(f)\n",
    "```\n",
    "\n",
    "- **Use Case**:\n",
    "  - When you need to save metadata or configurations rather than the full model.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. HDF5 (Hierarchical Data Format)**\n",
    "HDF5 is a binary data format that works well for saving structured data, including large datasets and numerical weights.\n",
    "\n",
    "- **Advantages**:\n",
    "  - Efficient storage of large arrays and hierarchical data.\n",
    "  - Can be used to save model weights in a structured format.\n",
    "\n",
    "- **Example (Keras)**:\n",
    "```python\n",
    "# Save the model\n",
    "model.save('model.h5')\n",
    "\n",
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model.h5')\n",
    "```\n",
    "\n",
    "- **Use Case**:\n",
    "  - TensorFlow/Keras models or scenarios requiring efficient hierarchical storage.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. PMML (Predictive Model Markup Language)**\n",
    "PMML is an XML-based standard for representing machine learning models. It is particularly useful for integrating with enterprise systems.\n",
    "\n",
    "- **Advantages**:\n",
    "  - Framework-agnostic and compatible with various tools and systems.\n",
    "  - Designed for enterprise-grade deployments.\n",
    "\n",
    "- **Example**:\n",
    "  - Export tools like **Nyoka** or **sklearn2pmml** can convert scikit-learn models to PMML.\n",
    "  ```python\n",
    "  from sklearn2pmml import sklearn2pmml\n",
    "  from sklearn2pmml.pipeline import PMMLPipeline\n",
    "\n",
    "  # Create PMML pipeline\n",
    "  pipeline = PMMLPipeline([(\"classifier\", model)])\n",
    "  sklearn2pmml(pipeline, \"model.pmml\", with_repr=True)\n",
    "  ```\n",
    "\n",
    "- **Use Case**:\n",
    "  - Enterprise systems requiring standardization and portability.\n",
    "\n",
    "---\n",
    "\n",
    "### **Comparison Table**\n",
    "\n",
    "| Method        | Framework-Specific | Portable | Human-Readable | Security Risks | Speed  | Use Case                                                                 |\n",
    "|---------------|--------------------|----------|----------------|----------------|--------|-------------------------------------------------------------------------|\n",
    "| **Joblib**    | No                 | Medium   | No             | Yes            | Fast   | Scikit-learn or numpy-based models.                                    |\n",
    "| **ONNX**      | No                 | High     | No             | Low            | Medium | Cross-platform deployments.                                            |\n",
    "| **SavedModel**| TensorFlow/Keras   | Medium   | No             | Low            | Medium | TensorFlow/Keras workflows.                                            |\n",
    "| **PyTorch**   | PyTorch            | Medium   | No             | Low            | Medium | PyTorch workflows.                                                     |\n",
    "| **JSON**      | No                 | High     | Yes            | Low            | Medium | Saving metadata or configurations.                                     |\n",
    "| **HDF5**      | TensorFlow/Keras   | Medium   | No             | Low            | Fast   | Efficient storage of large models.                                     |\n",
    "| **PMML**      | No                 | High     | Yes (XML)      | Low            | Medium | Enterprise systems requiring model standardization and portability.    |\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways**\n",
    "- **For scikit-learn models**: Use **Joblib** for efficiency.\n",
    "- **For cross-framework compatibility**: Use **ONNX**.\n",
    "- **For TensorFlow/Keras models**: Use the **SavedModel** format or HDF5.\n",
    "- **For PyTorch models**: Use PyTorch's native **torch.save** and **torch.load**.\n",
    "- **For metadata or configurations**: Use **JSON**.\n",
    "- **For enterprise integration**: Use **PMML**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with Joblib: [0]\n"
     ]
    }
   ],
   "source": [
    "#Joblib >>\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump, load\n",
    "\n",
    "# Train a model\n",
    "X, y = load_iris(return_X_y=True)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Save the model to a file\n",
    "dump(model, 'random_forest.joblib')\n",
    "\n",
    "# Load the model from the file\n",
    "loaded_model = load('random_forest.joblib')\n",
    "print(\"Model loaded with Joblib:\", loaded_model.predict([X[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as ONNX format.\n"
     ]
    }
   ],
   "source": [
    "#ONNX >>\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "\n",
    "# Simple PyTorch model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(4, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = SimpleModel()\n",
    "dummy_input = torch.randn(1, 4)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "torch.onnx.export(model, dummy_input, \"simple_model.onnx\")\n",
    "print(\"Model saved as ONNX format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Inference Output: [array([[-0.08513856,  0.14881259,  0.4237174 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(\"simple_model.onnx\")\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Run inference using ONNX Runtime\n",
    "session = ort.InferenceSession(\"simple_model.onnx\")\n",
    "inputs = {session.get_inputs()[0].name: np.random.randn(1, 4).astype(np.float32)}\n",
    "outputs = session.run(None, inputs)\n",
    "print(\"ONNX Inference Output:\", outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in HDF5 format.\n"
     ]
    }
   ],
   "source": [
    "#TensorFlow SavedModel Format >>\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Build a simple Keras model\n",
    "model = Sequential([Dense(10, activation='relu', input_shape=(4,)), Dense(1)])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Save the model in HDF5 format\n",
    "model.save('saved_model/my_model.h5')\n",
    "print(\"Model saved in HDF5 format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with TensorFlow SavedModel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 6 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Save the model in the correct path with .keras extension\n",
    "model.save('saved_model/my_model.keras')\n",
    "\n",
    "# Load the model using TensorFlow SavedModel\n",
    "loaded_model = tf.keras.models.load_model('saved_model/my_model.keras')\n",
    "print(\"Model loaded with TensorFlow SavedModel.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in PyTorch format.\n"
     ]
    }
   ],
   "source": [
    "#PyTorch Serialization >>\n",
    "import torch\n",
    "\n",
    "# Simple PyTorch model\n",
    "model = SimpleModel()\n",
    "\n",
    "# Save the model's state_dict\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Model saved in PyTorch format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded with PyTorch: tensor([[ 1.1150, -0.7315,  0.0927]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justo\\AppData\\Local\\Temp\\ipykernel_8792\\1489547615.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model.pth\"))\n"
     ]
    }
   ],
   "source": [
    "# Load the state_dict into a new instance of the model\n",
    "model = SimpleModel()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()\n",
    "print(\"Model loaded with PyTorch:\", model(torch.randn(1, 4)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved as JSON.\n"
     ]
    }
   ],
   "source": [
    "#JSON >>\n",
    "import json\n",
    "\n",
    "# Example model metadata\n",
    "model_metadata = {\n",
    "    \"model_name\": \"RandomForest\",\n",
    "    \"hyperparameters\": {\"n_estimators\": 100, \"max_depth\": 5},\n",
    "    \"input_features\": [\"feature1\", \"feature2\", \"feature3\"]\n",
    "}\n",
    "\n",
    "# Save metadata to a JSON file\n",
    "with open(\"model_metadata.json\", \"w\") as f:\n",
    "    json.dump(model_metadata, f, indent=4)\n",
    "print(\"Metadata saved as JSON.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Metadata: {'model_name': 'RandomForest', 'hyperparameters': {'n_estimators': 100, 'max_depth': 5}, 'input_features': ['feature1', 'feature2', 'feature3']}\n"
     ]
    }
   ],
   "source": [
    "# Load metadata from the JSON file\n",
    "with open(\"model_metadata.json\", \"r\") as f:\n",
    "    loaded_metadata = json.load(f)\n",
    "print(\"Loaded Metadata:\", loaded_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in PyTorch format.\n"
     ]
    }
   ],
   "source": [
    "# Save the PyTorch model's state_dict\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "print(\"Model saved in PyTorch format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in HDF5 format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m50\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">63</span> (256.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m63\u001b[0m (256.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61</span> (244.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m61\u001b[0m (244.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from HDF5: None\n"
     ]
    }
   ],
   "source": [
    "# Save the model to HDF5 format\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Build a simple Keras model\n",
    "model = Sequential([Dense(10, activation='relu', input_shape=(4,)), Dense(1)])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Save the model in HDF5 format\n",
    "model.save('model.h5')\n",
    "print(\"Model saved in HDF5 format.\")\n",
    "\n",
    "# Load the model from HDF5 format\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('model.h5')\n",
    "print(\"Model loaded from HDF5:\", loaded_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "Each format serves different use cases:\n",
    "- Use **Joblib** for simple, Python-based workflows.\n",
    "- Use **ONNX** for interoperability across frameworks.\n",
    "- Use **TensorFlow SavedModel** or **HDF5** for TensorFlow/Keras models.\n",
    "- Use **PyTorch Serialization** for PyTorch models.\n",
    "- Use **JSON** for storing metadata or configurations.\n",
    "- Use **PMML** for enterprise-grade, standardized deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. ***What is heteroscedasticity, and why is it a problem?***\n",
    "*Answer-*\n",
    "\n",
    "**`Heteroscedasticity`** occurs when the variability (variance) of the residuals (errors) in a regression model is not constant across all levels of the independent variable(s). In simpler terms, the spread of errors changes as the predicted values (or an independent variable) increase or decrease. This is the opposite of **homoscedasticity**, where the residuals have constant variance.\n",
    "\n",
    "#### Example:\n",
    "- In a homoscedastic dataset, the errors might look evenly spread across all levels of the independent variable.\n",
    "- In a heteroscedastic dataset, you might observe a \"funnel shape\" in a residual plot, where errors become larger or smaller as the fitted values increase.\n",
    "\n",
    "---\n",
    "\n",
    "### **Why is Heteroscedasticity a Problem?**\n",
    "\n",
    "Heteroscedasticity can lead to several issues in regression analysis:\n",
    "\n",
    "1. **Inefficient Estimates**:\n",
    "   - Ordinary Least Squares (OLS) assumes constant variance of errors. When heteroscedasticity is present, the OLS estimator is still unbiased but becomes inefficient. This means that the standard errors of the coefficients are no longer minimum, leading to less reliable parameter estimates.\n",
    "\n",
    "2. **Invalid Hypothesis Testing**:\n",
    "   - Standard errors are used to calculate t-statistics, p-values, and confidence intervals. Heteroscedasticity distorts these standard errors, making hypothesis tests for coefficients unreliable. This may result in:\n",
    "     - Overestimating or underestimating the significance of predictors.\n",
    "     - Incorrect conclusions about the relationships in the model.\n",
    "\n",
    "3. **Poor Predictive Performance**:\n",
    "   - The presence of heteroscedasticity can indicate that the model is missing key explanatory variables or has an incorrect functional form, which reduces the model's predictive accuracy.\n",
    "\n",
    "4. **Model Interpretation**:\n",
    "   - A model with heteroscedasticity might indicate that the relationship between the predictors and the outcome variable changes at different levels of the predictors, making interpretation difficult.\n",
    "\n",
    "---\n",
    "\n",
    "### **Detecting Heteroscedasticity**\n",
    "\n",
    "1. **Residual Plots**:\n",
    "   - Plot the residuals (errors) against the predicted values or an independent variable. A funnel-shaped pattern or increasing spread indicates heteroscedasticity.\n",
    "\n",
    "2. **Statistical Tests**:\n",
    "   - **Breusch-Pagan Test**: Tests if the variance of residuals depends on the independent variables.\n",
    "   - **White Test**: A more general test that can detect heteroscedasticity regardless of its form.\n",
    "\n",
    "3. **Quantitative Measures**:\n",
    "   - Look for patterns in the residuals' standard deviation or conduct variance checks over different ranges of the data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Addressing Heteroscedasticity**\n",
    "\n",
    "If heteroscedasticity is detected, several remedies can address the problem:\n",
    "\n",
    "1. **Transforming the Dependent Variable**:\n",
    "   - Apply a logarithmic, square root, or other transformation to stabilize the variance of the errors. For example:\n",
    "     ```python\n",
    "     y_transformed = np.log(y)  # Log transformation\n",
    "     ```\n",
    "\n",
    "2. **Weighted Least Squares (WLS)**:\n",
    "   - Assign weights to each observation to give less importance to observations with higher variance.\n",
    "\n",
    "3. **Robust Standard Errors**:\n",
    "   - Use heteroscedasticity-robust standard errors to correct the standard error estimates while keeping the original model.\n",
    "\n",
    "4. **Add Missing Variables**:\n",
    "   - Heteroscedasticity might indicate the omission of important predictors. Adding relevant variables may reduce the variance inconsistency.\n",
    "\n",
    "5. **Use Generalized Linear Models (GLMs)**:\n",
    "   - GLMs allow for modeling non-constant variance directly using appropriate link functions.\n",
    "\n",
    "6. **Box-Cox Transformation**:\n",
    "   - The Box-Cox transformation automatically finds the best transformation to stabilize variance.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "Heteroscedasticity violates a key assumption of linear regression and undermines the reliability of the model. Detecting and addressing it ensures better efficiency, valid hypothesis testing, and accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breusch-Pagan p-value: 0.0088\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "X = np.linspace(1, 100, 100)\n",
    "y = 5 * X + np.random.normal(0, X**0.5, 100)  # Heteroscedastic data\n",
    "\n",
    "# Fit a regression model\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Residual plot\n",
    "residuals = model.resid\n",
    "fitted = model.fittedvalues\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(fitted, residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()\n",
    "\n",
    "# Perform the Breusch-Pagan Test\n",
    "test_stat, p_value, _, _ = het_breuschpagan(residuals, X)\n",
    "print(f\"Breusch-Pagan p-value: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            WLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.998\n",
      "Model:                            WLS   Adj. R-squared:                  0.998\n",
      "Method:                 Least Squares   F-statistic:                 6.379e+04\n",
      "Date:                Sun, 26 Jan 2025   Prob (F-statistic):          1.03e-139\n",
      "Time:                        20:21:35   Log-Likelihood:                -333.62\n",
      "No. Observations:                 100   AIC:                             671.2\n",
      "Df Residuals:                      98   BIC:                             676.4\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.5283      0.129      4.080      0.000       0.271       0.785\n",
      "x1             4.9637      0.020    252.558      0.000       4.925       5.003\n",
      "==============================================================================\n",
      "Omnibus:                       12.875   Durbin-Watson:                   1.938\n",
      "Prob(Omnibus):                  0.002   Jarque-Bera (JB):               27.622\n",
      "Skew:                           0.409   Prob(JB):                     1.00e-06\n",
      "Kurtosis:                       5.442   Cond. No.                         7.19\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#### **Addressing Heteroscedasticity**:\n",
    "\n",
    "weights = 1 / (fitted ** 2)  # Example weights\n",
    "wls_model = sm.WLS(y, X, weights=weights).fit()\n",
    "print(wls_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.998\n",
      "Model:                            OLS   Adj. R-squared:                  0.998\n",
      "Method:                 Least Squares   F-statistic:                 6.198e+04\n",
      "Date:                Sun, 26 Jan 2025   Prob (F-statistic):          4.19e-139\n",
      "Time:                        20:21:38   Log-Likelihood:                -325.67\n",
      "No. Observations:                 100   AIC:                             655.3\n",
      "Df Residuals:                      98   BIC:                             660.5\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.0816      0.878     -1.231      0.221      -2.825       0.661\n",
      "x1             5.0083      0.020    248.952      0.000       4.968       5.048\n",
      "==============================================================================\n",
      "Omnibus:                        6.993   Durbin-Watson:                   2.159\n",
      "Prob(Omnibus):                  0.030   Jarque-Bera (JB):                7.880\n",
      "Skew:                          -0.397   Prob(JB):                       0.0194\n",
      "Kurtosis:                       4.123   Cond. No.                         117.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n"
     ]
    }
   ],
   "source": [
    "robust_model = model.get_robustcov_results(cov_type='HC3')\n",
    "print(robust_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. ***How can interaction terms enhance a regression model’s predictive power?***\n",
    "*Answer-*\n",
    "\n",
    "Interaction terms in a regression model capture the effect of two (or more) predictor variables interacting with each other. Instead of assuming the predictors have only additive effects, interaction terms allow for the possibility that the effect of one variable depends on the level of another variable.\n",
    "\n",
    "For example:\n",
    "- Suppose you’re modeling the effect of **education level** and **experience** on **salary**. If the influence of education on salary changes depending on the level of experience, an interaction term like `education × experience` would be appropriate.\n",
    "\n",
    "---\n",
    "\n",
    "### **Benefits of Using Interaction Terms**\n",
    "\n",
    "1. **Capturing Non-Additive Effects**:\n",
    "   - Interaction terms allow the model to account for cases where the combined effect of two variables differs from the sum of their individual effects. Without interaction terms, such relationships would be overlooked.\n",
    "\n",
    "2. **Improved Predictive Power**:\n",
    "   - By modeling the combined effects of variables, the regression can explain more variance in the dependent variable, leading to better predictions.\n",
    "\n",
    "3. **Realistic Representations of Relationships**:\n",
    "   - Many real-world phenomena involve interactions. For instance:\n",
    "     - The effectiveness of a marketing campaign might depend on customer demographics.\n",
    "     - The effect of medication could depend on age and dosage combined.\n",
    "   - Including interaction terms makes the model more reflective of these relationships.\n",
    "\n",
    "4. **Insights into Complex Relationships**:\n",
    "   - Interaction terms reveal how predictor variables influence each other. This can provide valuable insights, especially in domains like social sciences, economics, and biology.\n",
    "\n",
    "5. **Non-Linearity Without Transformations**:\n",
    "   - Interaction terms can introduce a form of non-linearity into the model without explicitly transforming variables. For example, \\(X_1 \\times X_2\\) is nonlinear even if \\(X_1\\) and \\(X_2\\) are linear.\n",
    "\n",
    "---\n",
    "\n",
    "### **Interpreting Interaction Terms**\n",
    "\n",
    "1. **Main Effects (\\(\\beta_1\\) and \\(\\beta_2\\))**:\n",
    "   - These represent the individual contributions of \\(X_1\\) and \\(X_2\\) to \\(y\\), holding the other variable constant at zero.\n",
    "\n",
    "2. **Interaction Effect (\\(\\beta_3\\))**:\n",
    "   - Indicates how much the relationship between \\(X_1\\) and \\(y\\) changes for a one-unit increase in \\(X_2\\) (or vice versa).\n",
    "\n",
    "---\n",
    "\n",
    "### **Potential Issues with Interaction Terms**\n",
    "\n",
    "1. **Multicollinearity**:\n",
    "   - Interaction terms are often highly correlated with their constituent variables, which can increase multicollinearity. Centering the variables (subtracting their mean) before creating interaction terms can reduce this issue.\n",
    "\n",
    "2. **Overfitting**:\n",
    "   - Including too many interaction terms (especially in high-dimensional data) can lead to overfitting. Regularization techniques like Ridge or Lasso regression can help mitigate this.\n",
    "\n",
    "3. **Interpretability**:\n",
    "   - Models with multiple interaction terms can become complex and harder to interpret.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**\n",
    "\n",
    "Interaction terms can significantly improve the predictive power and realism of a regression model by capturing relationships that simple additive terms cannot. They’re especially useful in situations where the effect of one variable depends on the level of another. However, care must be taken to manage multicollinearity and overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.995\n",
      "Model:                            OLS   Adj. R-squared:                  0.989\n",
      "Method:                 Least Squares   F-statistic:                     185.4\n",
      "Date:                Sun, 26 Jan 2025   Prob (F-statistic):            0.00537\n",
      "Time:                        20:21:47   Log-Likelihood:                -1.1142\n",
      "No. Observations:                   5   AIC:                             8.228\n",
      "Df Residuals:                       2   BIC:                             7.057\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.4667      0.972      0.480      0.679      -3.715       4.649\n",
      "X1             0.4667      0.932      0.501      0.666      -3.543       4.477\n",
      "X2             0.9333      0.123      7.561      0.017       0.402       1.464\n",
      "X1_X2          0.2143      0.128      1.677      0.236      -0.335       0.764\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   2.721\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.677\n",
      "Skew:                           0.729   Prob(JB):                        0.713\n",
      "Kurtosis:                       1.940   Cond. No.                     1.97e+17\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.19e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    }
   ],
   "source": [
    "# How to include terms >>\n",
    "#1. Manual Inclusion >>\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Example dataset\n",
    "data = pd.DataFrame({\n",
    "    'X1': [1, 2, 3, 4, 5],\n",
    "    'X2': [2, 3, 4, 5, 6],\n",
    "    'y': [3, 6, 8, 11, 15]\n",
    "})\n",
    "\n",
    "# Adding an interaction term\n",
    "data['X1_X2'] = data['X1'] * data['X2']\n",
    "\n",
    "# Fit a regression model\n",
    "X = sm.add_constant(data[['X1', 'X2', 'X1_X2']])\n",
    "y = data['y']\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.995\n",
      "Model:                            OLS   Adj. R-squared:                  0.989\n",
      "Method:                 Least Squares   F-statistic:                     185.4\n",
      "Date:                Sun, 26 Jan 2025   Prob (F-statistic):            0.00537\n",
      "Time:                        20:21:49   Log-Likelihood:                -1.1142\n",
      "No. Observations:                   5   AIC:                             8.228\n",
      "Df Residuals:                       2   BIC:                             7.057\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.4667      0.972      0.480      0.679      -3.715       4.649\n",
      "X1             0.4667      0.932      0.501      0.666      -3.543       4.477\n",
      "X2             0.9333      0.123      7.561      0.017       0.402       1.464\n",
      "X1:X2          0.2143      0.128      1.677      0.236      -0.335       0.764\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   2.721\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.677\n",
      "Skew:                           0.729   Prob(JB):                        0.713\n",
      "Kurtosis:                       1.940   Cond. No.                     1.97e+17\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.19e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n"
     ]
    }
   ],
   "source": [
    "# Using formula APIs >>\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Interaction term using formula syntax\n",
    "model = smf.ols(formula='y ~ X1 * X2', data=data).fit()\n",
    "print(model.summary())\n",
    "\n",
    "## The X1 * X2 syntax automatically includes: X1, X2, and X1 * X2 (interaction term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.7        0.7        0.21428571]\n",
      "Intercept: 0.6999999999999966\n"
     ]
    }
   ],
   "source": [
    "# Using Scikit-learn >>\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Example dataset\n",
    "X = data[['X1', 'X2']]\n",
    "y = data['y']\n",
    "\n",
    "# Generate interaction terms\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_interactions = poly.fit_transform(X)\n",
    "\n",
    "# Fit a regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_interactions, y)\n",
    "\n",
    "print(\"Coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
